{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import s3fs\n",
    "import dask\n",
    "import dash\n",
    "import requests\n",
    "\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd \n",
    "import cartopy.crs as ccrs\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.dates as mdates \n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.patheffects as path_effects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imos-data/UNSW/NRS_extremes/Temperature_DataProducts_v2/MAI090',\n",
       " 'imos-data/UNSW/NRS_extremes/Temperature_DataProducts_v2/PH050',\n",
       " 'imos-data/UNSW/NRS_extremes/Temperature_DataProducts_v2/PH100',\n",
       " 'imos-data/UNSW/NRS_extremes/Temperature_DataProducts_v2/ROT055']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in methods for reading, writing, and managing files stored in S3. The connection is made anonamously. \n",
    "s3 = s3fs.S3FileSystem(anon=True) \n",
    "# List all data folders available from UNSW\n",
    "s3_bucket_name = \"imos-data/\"\n",
    "s3_org_name = \"UNSW/\"\n",
    "s3_product = \"NRS_extremes/Temperature_DataProducts_v2\"\n",
    "data_folders = s3.ls(f\"{s3_bucket_name}{s3_org_name}{s3_product}\")\n",
    "# List all subfolders under the product directory\n",
    "data_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets into Memory (explicit load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store datasets\n",
    "datasets = {}\n",
    "\n",
    "# Iterate through each subfolder and load .nc files\n",
    "for folder in data_folders:\n",
    "    # List files in the current folder\n",
    "    files_in_folder = s3.ls(folder)\n",
    "    \n",
    "    # Filter for .nc files\n",
    "    nc_files = [file for file in files_in_folder if file.endswith(\".nc\")]\n",
    "    \n",
    "    # Load each .nc file into memory\n",
    "    for nc_file in nc_files:\n",
    "        # Open the file using s3fs and load the dataset into memory with xarray\n",
    "        with s3.open(nc_file, mode='rb') as f:\n",
    "            ds = xr.open_dataset(f, engine=\"h5netcdf\")\n",
    "            ds.load()  # Explicitly load the dataset into memory\n",
    "        \n",
    "        # Add to the datasets dictionary using the folder name as the key\n",
    "        datasets[folder] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimised to variables download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['MAI090', 'PH050', 'PH100', 'ROT055'])\n"
     ]
    }
   ],
   "source": [
    "# Define the variables you want to extract, including \"TEMP_PER10\", \"TEMP_PER90\", and \"TEMP_MEAN\"\n",
    "variables_to_extract = [\"TIME\", \"TEMP_COLD_SPIKE\", \"TEMP_HEAT_SPIKE\", \"TEMP_PER10\", \"TEMP_PER90\", \"TEMP_MEAN\"]\n",
    "\n",
    "# Initialize an empty dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Iterate through each subfolder and process .nc files\n",
    "for folder in data_folders:\n",
    "    # List files in the current folder\n",
    "    files_in_folder = s3.ls(folder)\n",
    "    \n",
    "    # Filter for .nc files\n",
    "    nc_files = [file for file in files_in_folder if file.endswith(\".nc\")]\n",
    "    \n",
    "    # Extract the last part of the folder name to use as the key\n",
    "    folder_key = folder.rstrip('/').split('/')[-1]\n",
    "    \n",
    "    # Load each .nc file into memory and process it\n",
    "    for nc_file in nc_files:\n",
    "        # Open the file using s3fs and load the dataset into memory with xarray\n",
    "        with s3.open(nc_file, mode='rb') as f:\n",
    "            ds = xr.open_dataset(f, engine=\"h5netcdf\", chunks={})\n",
    "\n",
    "            # Extract the lat/lon attributes\n",
    "            lat = ds.attrs.get('geospatial_lat_max')\n",
    "            lon = ds.attrs.get('geospatial_lon_max')\n",
    "            \n",
    "            # Extract only the specified variables and their attributes\n",
    "            if all(var in ds.variables for var in variables_to_extract):\n",
    "                extracted_ds = ds[variables_to_extract].load()\n",
    "                \n",
    "                # Convert the dataset to a DataFrame\n",
    "                df = extracted_ds.to_dataframe().reset_index()\n",
    "                \n",
    "                # Add lat and lon columns to the DataFrame\n",
    "                df['lat'] = lat\n",
    "                df['lon'] = lon\n",
    "                \n",
    "                # Calculate the intervals for heat spikes and cold spikes\n",
    "                df['heat_spike_diff'] = df['TEMP_HEAT_SPIKE'] - df['TEMP_PER90']\n",
    "                df['cold_spike_diff'] = df['TEMP_PER10'] - df['TEMP_COLD_SPIKE']\n",
    "                \n",
    "                # Calculate the interval range between TEMP_MEAN and the percentiles\n",
    "                df['temp_interval'] = df['TEMP_PER90'] - df['TEMP_MEAN']\n",
    "                \n",
    "                # Classify spikes into categories based on the intervals\n",
    "                def classify_spike(temp_diff, interval):\n",
    "                    if pd.isna(temp_diff):\n",
    "                        return None  # No spike\n",
    "                    elif temp_diff < interval:\n",
    "                        return 0  # Within 90th percentile\n",
    "                    elif interval <= temp_diff < 2 * interval:\n",
    "                        return 1  # 1-2 times the interval\n",
    "                    elif 2 * interval <= temp_diff < 3 * interval:\n",
    "                        return 2  # 2-3 times the interval\n",
    "                    elif 3 * interval <= temp_diff < 4 * interval:\n",
    "                        return 3  # 3-4 times the interval\n",
    "                    else:\n",
    "                        return 4  # 4+ times the interval\n",
    "                \n",
    "                # Apply the classification logic to both heat and cold spikes\n",
    "                df['heat_spike_category'] = df.apply(lambda row: classify_spike(row['heat_spike_diff'], row['temp_interval']), axis=1)\n",
    "                df['cold_spike_category'] = df.apply(lambda row: classify_spike(row['cold_spike_diff'], row['temp_interval']), axis=1)\n",
    "                \n",
    "                # Store the DataFrame in the dictionary using the folder's last part as the key\n",
    "                if folder_key in dataframes:\n",
    "                    # If the folder_key already exists, append to the existing DataFrame\n",
    "                    dataframes[folder_key] = pd.concat([dataframes[folder_key], df], ignore_index=True)\n",
    "                else:\n",
    "                    # If the folder_key does not exist, initialize it with the current DataFrame\n",
    "                    dataframes[folder_key] = df\n",
    "            else:\n",
    "                print(f\"Missing one or more variables in file: {nc_file}\")\n",
    "            \n",
    "            # Explicitly close the dataset to free memory\n",
    "            ds.close()\n",
    "\n",
    "# Print the keys to verify\n",
    "print(dataframes.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAI090':                      TIME  DEPTH  TEMP_COLD_SPIKE  TEMP_HEAT_SPIKE  \\\n",
       " 0     1944-01-02 12:00:00    2.0              NaN              NaN   \n",
       " 1     1944-01-02 12:00:00   21.0              NaN              NaN   \n",
       " 2     1944-01-03 12:00:00    2.0              NaN              NaN   \n",
       " 3     1944-01-03 12:00:00   21.0              NaN              NaN   \n",
       " 4     1944-01-04 12:00:00    2.0              NaN              NaN   \n",
       " ...                   ...    ...              ...              ...   \n",
       " 58347 2023-11-16 12:00:00   21.0              NaN              NaN   \n",
       " 58348 2023-11-17 12:00:00    2.0              NaN              NaN   \n",
       " 58349 2023-11-17 12:00:00   21.0              NaN              NaN   \n",
       " 58350 2023-11-18 12:00:00    2.0              NaN              NaN   \n",
       " 58351 2023-11-18 12:00:00   21.0              NaN              NaN   \n",
       " \n",
       "        TEMP_PER10  TEMP_PER90  TEMP_MEAN    lat    lon  heat_spike_diff  \\\n",
       " 0       14.367753   17.349215  15.805466 -42.52  148.3              NaN   \n",
       " 1       14.032993   16.412550  15.269378 -42.52  148.3              NaN   \n",
       " 2       14.398947   17.366240  15.844111 -42.52  148.3              NaN   \n",
       " 3       14.068525   16.454115  15.308929 -42.52  148.3              NaN   \n",
       " 4       14.431046   17.389423  15.888153 -42.52  148.3              NaN   \n",
       " ...           ...         ...        ...    ...    ...              ...   \n",
       " 58347   12.208220   14.154654  13.225665 -42.52  148.3              NaN   \n",
       " 58348   12.452065   14.661288  13.580489 -42.52  148.3              NaN   \n",
       " 58349   12.241037   14.188922  13.257289 -42.52  148.3              NaN   \n",
       " 58350   12.475758   14.706029  13.621202 -42.52  148.3              NaN   \n",
       " 58351   12.274700   14.231761  13.295248 -42.52  148.3              NaN   \n",
       " \n",
       "        cold_spike_diff  temp_interval  heat_spike_category  \\\n",
       " 0                  NaN       1.543749                  NaN   \n",
       " 1                  NaN       1.143172                  NaN   \n",
       " 2                  NaN       1.522128                  NaN   \n",
       " 3                  NaN       1.145185                  NaN   \n",
       " 4                  NaN       1.501270                  NaN   \n",
       " ...                ...            ...                  ...   \n",
       " 58347              NaN       0.928988                  NaN   \n",
       " 58348              NaN       1.080799                  NaN   \n",
       " 58349              NaN       0.931633                  NaN   \n",
       " 58350              NaN       1.084826                  NaN   \n",
       " 58351              NaN       0.936513                  NaN   \n",
       " \n",
       "        cold_spike_category  \n",
       " 0                      NaN  \n",
       " 1                      NaN  \n",
       " 2                      NaN  \n",
       " 3                      NaN  \n",
       " 4                      NaN  \n",
       " ...                    ...  \n",
       " 58347                  NaN  \n",
       " 58348                  NaN  \n",
       " 58349                  NaN  \n",
       " 58350                  NaN  \n",
       " 58351                  NaN  \n",
       " \n",
       " [58352 rows x 14 columns],\n",
       " 'PH050':                       TIME  DEPTH  TEMP_COLD_SPIKE  TEMP_HEAT_SPIKE  \\\n",
       " 0      1942-01-02 12:00:00    2.0              NaN              NaN   \n",
       " 1      1942-01-02 12:00:00   10.0              NaN              NaN   \n",
       " 2      1942-01-02 12:00:00   20.0              NaN              NaN   \n",
       " 3      1942-01-02 12:00:00   31.0              NaN              NaN   \n",
       " 4      1942-01-02 12:00:00   40.0              NaN              NaN   \n",
       " ...                    ...    ...              ...              ...   \n",
       " 179275 2023-10-23 12:00:00   10.0              NaN              NaN   \n",
       " 179276 2023-10-23 12:00:00   20.0              NaN              NaN   \n",
       " 179277 2023-10-23 12:00:00   31.0              NaN              NaN   \n",
       " 179278 2023-10-23 12:00:00   40.0              NaN              NaN   \n",
       " 179279 2023-10-23 12:00:00   48.0              NaN              NaN   \n",
       " \n",
       "         TEMP_PER10  TEMP_PER90  TEMP_MEAN    lat     lon  heat_spike_diff  \\\n",
       " 0        19.475739   21.978048  20.747995 -34.02  151.25              NaN   \n",
       " 1        18.419100   21.718147  20.250793 -34.02  151.25              NaN   \n",
       " 2        17.156858   21.055687  19.303995 -34.02  151.25              NaN   \n",
       " 3        15.983730   20.150331  18.141619 -34.02  151.25              NaN   \n",
       " 4        15.301175   19.485348  17.322882 -34.02  151.25              NaN   \n",
       " ...            ...         ...        ...    ...     ...              ...   \n",
       " 179275   16.174934   18.680944  17.509428 -34.02  151.25              NaN   \n",
       " 179276   15.572659   18.356693  17.028461 -34.02  151.25              NaN   \n",
       " 179277   14.885924   17.936174  16.441027 -34.02  151.25              NaN   \n",
       " 179278   14.338751   17.534966  15.943305 -34.02  151.25              NaN   \n",
       " 179279   14.078856   17.045080  15.566672 -34.02  151.25              NaN   \n",
       " \n",
       "         cold_spike_diff  temp_interval  heat_spike_category  \\\n",
       " 0                   NaN       1.230053                  NaN   \n",
       " 1                   NaN       1.467354                  NaN   \n",
       " 2                   NaN       1.751692                  NaN   \n",
       " 3                   NaN       2.008713                  NaN   \n",
       " 4                   NaN       2.162466                  NaN   \n",
       " ...                 ...            ...                  ...   \n",
       " 179275              NaN       1.171516                  NaN   \n",
       " 179276              NaN       1.328232                  NaN   \n",
       " 179277              NaN       1.495148                  NaN   \n",
       " 179278              NaN       1.591660                  NaN   \n",
       " 179279              NaN       1.478408                  NaN   \n",
       " \n",
       "         cold_spike_category  \n",
       " 0                       NaN  \n",
       " 1                       NaN  \n",
       " 2                       NaN  \n",
       " 3                       NaN  \n",
       " 4                       NaN  \n",
       " ...                     ...  \n",
       " 179275                  NaN  \n",
       " 179276                  NaN  \n",
       " 179277                  NaN  \n",
       " 179278                  NaN  \n",
       " 179279                  NaN  \n",
       " \n",
       " [179280 rows x 14 columns],\n",
       " 'PH100':                       TIME  DEPTH  TEMP_COLD_SPIKE  TEMP_HEAT_SPIKE  \\\n",
       " 0      1953-01-02 12:00:00    2.0              NaN              NaN   \n",
       " 1      1953-01-02 12:00:00   22.0              NaN              NaN   \n",
       " 2      1953-01-02 12:00:00   40.0              NaN              NaN   \n",
       " 3      1953-01-02 12:00:00   50.0              NaN              NaN   \n",
       " 4      1953-01-02 12:00:00   59.0              NaN              NaN   \n",
       " ...                    ...    ...              ...              ...   \n",
       " 181414 2023-12-17 12:00:00   40.0              NaN              NaN   \n",
       " 181415 2023-12-17 12:00:00   50.0              NaN              NaN   \n",
       " 181416 2023-12-17 12:00:00   59.0              NaN              NaN   \n",
       " 181417 2023-12-17 12:00:00   75.0              NaN              NaN   \n",
       " 181418 2023-12-17 12:00:00   98.0              NaN              NaN   \n",
       " \n",
       "         TEMP_PER10  TEMP_PER90  TEMP_MEAN    lat     lon  heat_spike_diff  \\\n",
       " 0        20.137583   22.422752  21.301796 -34.03  151.27              NaN   \n",
       " 1        17.906080   21.150036  19.634720 -34.03  151.27              NaN   \n",
       " 2        15.986550   19.785873  17.886005 -34.03  151.27              NaN   \n",
       " 3        15.212172   18.915106  16.986380 -34.03  151.27              NaN   \n",
       " 4        14.892512   18.151787  16.423357 -34.03  151.27              NaN   \n",
       " ...            ...         ...        ...    ...     ...              ...   \n",
       " 181414   16.001019   19.372147  17.674072 -34.03  151.27              NaN   \n",
       " 181415   15.215949   18.475618  16.829412 -34.03  151.27              NaN   \n",
       " 181416   14.859074   17.740385  16.269806 -34.03  151.27              NaN   \n",
       " 181417   14.308675   16.919792  15.487443 -34.03  151.27              NaN   \n",
       " 181418   13.800268   15.870316  14.782347 -34.03  151.27              NaN   \n",
       " \n",
       "         cold_spike_diff  temp_interval  heat_spike_category  \\\n",
       " 0                   NaN       1.120956                  NaN   \n",
       " 1                   NaN       1.515316                  NaN   \n",
       " 2                   NaN       1.899868                  NaN   \n",
       " 3                   NaN       1.928726                  NaN   \n",
       " 4                   NaN       1.728430                  NaN   \n",
       " ...                 ...            ...                  ...   \n",
       " 181414              NaN       1.698074                  NaN   \n",
       " 181415              NaN       1.646206                  NaN   \n",
       " 181416              NaN       1.470579                  NaN   \n",
       " 181417              NaN       1.432349                  NaN   \n",
       " 181418              NaN       1.087969                  NaN   \n",
       " \n",
       "         cold_spike_category  \n",
       " 0                       NaN  \n",
       " 1                       NaN  \n",
       " 2                       NaN  \n",
       " 3                       NaN  \n",
       " 4                       NaN  \n",
       " ...                     ...  \n",
       " 181414                  NaN  \n",
       " 181415                  NaN  \n",
       " 181416                  NaN  \n",
       " 181417                  NaN  \n",
       " 181418                  NaN  \n",
       " \n",
       " [181419 rows x 14 columns],\n",
       " 'ROT055':                       TIME  DEPTH  TEMP_COLD_SPIKE  TEMP_HEAT_SPIKE  \\\n",
       " 0      1951-01-02 12:00:00    2.0              NaN              NaN   \n",
       " 1      1951-01-02 12:00:00   29.0              NaN              NaN   \n",
       " 2      1951-01-02 12:00:00   38.0              NaN              NaN   \n",
       " 3      1951-01-02 12:00:00   47.0              NaN              NaN   \n",
       " 4      1951-01-03 12:00:00    2.0              NaN              NaN   \n",
       " ...                    ...    ...              ...              ...   \n",
       " 106507 2023-11-26 12:00:00   47.0              NaN              NaN   \n",
       " 106508 2023-11-27 12:00:00    2.0              NaN              NaN   \n",
       " 106509 2023-11-27 12:00:00   29.0              NaN              NaN   \n",
       " 106510 2023-11-27 12:00:00   38.0              NaN              NaN   \n",
       " 106511 2023-11-27 12:00:00   47.0              NaN              NaN   \n",
       " \n",
       "         TEMP_PER10  TEMP_PER90  TEMP_MEAN    lat     lon  heat_spike_diff  \\\n",
       " 0        20.203041   22.188120  21.130072 -31.93  115.45              NaN   \n",
       " 1        19.691460   21.592833  20.570498 -31.93  115.45              NaN   \n",
       " 2        19.324778   21.339029  20.299126 -31.93  115.45              NaN   \n",
       " 3        18.851215   21.023861  19.957500 -31.93  115.45              NaN   \n",
       " 4        20.236420   22.210402  21.160950 -31.93  115.45              NaN   \n",
       " ...            ...         ...        ...    ...     ...              ...   \n",
       " 106507   18.339283   20.208694  19.284782 -31.93  115.45              NaN   \n",
       " 106508   19.019613   20.664345  19.855694 -31.93  115.45              NaN   \n",
       " 106509   18.712049   20.413282  19.618546 -31.93  115.45              NaN   \n",
       " 106510   18.541206   20.313707  19.469580 -31.93  115.45              NaN   \n",
       " 106511   18.340706   20.219656  19.297571 -31.93  115.45              NaN   \n",
       " \n",
       "         cold_spike_diff  temp_interval  heat_spike_category  \\\n",
       " 0                   NaN       1.058048                  NaN   \n",
       " 1                   NaN       1.022335                  NaN   \n",
       " 2                   NaN       1.039904                  NaN   \n",
       " 3                   NaN       1.066360                  NaN   \n",
       " 4                   NaN       1.049452                  NaN   \n",
       " ...                 ...            ...                  ...   \n",
       " 106507              NaN       0.923912                  NaN   \n",
       " 106508              NaN       0.808651                  NaN   \n",
       " 106509              NaN       0.794737                  NaN   \n",
       " 106510              NaN       0.844128                  NaN   \n",
       " 106511              NaN       0.922085                  NaN   \n",
       " \n",
       "         cold_spike_category  \n",
       " 0                       NaN  \n",
       " 1                       NaN  \n",
       " 2                       NaN  \n",
       " 3                       NaN  \n",
       " 4                       NaN  \n",
       " ...                     ...  \n",
       " 106507                  NaN  \n",
       " 106508                  NaN  \n",
       " 106509                  NaN  \n",
       " 106510                  NaN  \n",
       " 106511                  NaN  \n",
       " \n",
       " [106512 rows x 14 columns]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Show location of stations in the Climatology directory\n",
    "\n",
    "Can only be used if the datasets() xarray is being implemented in the download section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and a map with coastlines\n",
    "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# Add coastlines and land features\n",
    "ax.coastlines(resolution='50m')\n",
    "ax.add_feature(cfeature.LAND, edgecolor='black', facecolor='lightgrey')\n",
    "\n",
    "# Set the extent to focus on Australia (bounding box coordinates)\n",
    "ax.set_extent([110, 160, -45, -10], crs=ccrs.PlateCarree())  # [lon_min, lon_max, lat_min, lat_max]\n",
    "\n",
    "\n",
    "# Iterate over datasets to plot the \"O\" at geospatial_lat_max and geospatial_lon_max\n",
    "for folder, ds in datasets.items():\n",
    "    # Extract latitude and longitude from the dataset attributes\n",
    "    lat = ds.attrs.get('geospatial_lat_max')\n",
    "    lon = ds.attrs.get('geospatial_lon_max')\n",
    "    \n",
    "    # Check if the attributes exist before plotting\n",
    "    if lat is not None and lon is not None:\n",
    "        # Plot a big \"O\" at the location\n",
    "        ax.text(lon, lat, 'O', fontsize=10, color='red', ha='center', va='center',\n",
    "                transform=ccrs.PlateCarree())\n",
    "\n",
    "# Set title and show plot\n",
    "ax.set_title('Locations of Geospatial Maxima')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and interactive date picker with the colour coded spikes\n",
    "\n",
    "Can only be used if the datasets() xarray is being implemented in the download section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddb950848944accbb558845cf159b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(DatePicker(value=Timestamp('2018-11-30 00:00:00'), description='Select Date', step=1), O…"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to convert date to \"days since 1950-01-01\"\n",
    "def date_to_days_since_1950(date):\n",
    "    ref_date = pd.to_datetime(\"1950-01-01\")\n",
    "    delta = date - ref_date\n",
    "    return delta.days\n",
    "\n",
    "# Function to update the plot\n",
    "def update_plot(date):\n",
    "    # Convert selected date to \"days since 1950-01-01\"\n",
    "    target_days = date_to_days_since_1950(pd.to_datetime(date))\n",
    "    \n",
    "    # Create a figure and a map with coastlines\n",
    "    fig, ax = plt.subplots(figsize=(12, 12), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    ax.coastlines(resolution='50m')\n",
    "    ax.add_feature(cfeature.LAND, edgecolor='black', facecolor='lightgrey')\n",
    "    ax.set_extent([110, 160, -45, -10], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Iterate over datasets to plot markers\n",
    "    for folder, ds in datasets.items():\n",
    "        lat = ds.attrs.get('geospatial_lat_max')\n",
    "        lon = ds.attrs.get('geospatial_lon_max')\n",
    "        \n",
    "        if lat is not None and lon is not None:\n",
    "            # TIME is already in datetime64 format, so no need for timedelta conversion\n",
    "            time_in_days = (ds['TIME'].values - np.datetime64(\"1950-01-01\")) / np.timedelta64(1, 'D')\n",
    "\n",
    "            # Find the index for the selected date in days since 1950\n",
    "            date_idx = np.isclose(time_in_days, target_days, atol=0.5)  # use a tolerance for floating point comparisons\n",
    "            \n",
    "            if date_idx.any():\n",
    "                temp_heat_spike = ds['TEMP_HEAT_SPIKE'].values[date_idx]\n",
    "                temp_cold_spike = ds['TEMP_COLD_SPIKE'].values[date_idx]\n",
    "                \n",
    "                if not pd.isna(temp_heat_spike).all():\n",
    "                    ax.plot(lon, lat, 'o', markersize=10, color='red', markeredgecolor='black', markeredgewidth=1.5,\n",
    "                            transform=ccrs.PlateCarree())\n",
    "                elif not pd.isna(temp_cold_spike).all():\n",
    "                    ax.plot(lon, lat, 'o', markersize=10, color='blue', markeredgecolor='black', markeredgewidth=1.5,\n",
    "                            transform=ccrs.PlateCarree())\n",
    "                else:\n",
    "                    ax.text(lon, lat, 'O', fontsize=15, color='black', ha='center', va='center',\n",
    "                            transform=ccrs.PlateCarree())\n",
    "    \n",
    "    ax.set_title(f'Heat and Cold Spikes on {date}')\n",
    "    plt.show()\n",
    "\n",
    "# Create a date picker widget\n",
    "date_picker = widgets.DatePicker(\n",
    "    description='Select Date',\n",
    "    value=pd.to_datetime(\"2018-11-30\") # Date happens to be a Heatwave and a Cold spike at the same time east and west.\n",
    ")\n",
    "\n",
    "# Create an interactive function to trigger the plot update when the date changes\n",
    "widgets.interactive(update_plot, date=date_picker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt at Bokeh to HTML\n",
    "\n",
    "Can only be used if the datasets() xarray is being implemented in the download section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"d2d9eed1-5dc2-4f32-83d5-7223a3b5acc4\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"d2d9eed1-5dc2-4f32-83d5-7223a3b5acc4\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.5.2.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"d2d9eed1-5dc2-4f32-83d5-7223a3b5acc4\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n",
      "WARNING:bokeh.embed.util:\n",
      "You are generating standalone HTML/JS output, but trying to use real Python\n",
      "callbacks (i.e. with on_change or on_event). This combination cannot work.\n",
      "\n",
      "Only JavaScript callbacks may be used with standalone output. For more\n",
      "information on JavaScript callbacks with Bokeh, see:\n",
      "\n",
      "    https://docs.bokeh.org/en/latest/docs/user_guide/interaction/js_callbacks.html\n",
      "\n",
      "Alternatively, to use real Python callbacks, a Bokeh server application may\n",
      "be used. For more information on building and running Bokeh applications, see:\n",
      "\n",
      "    https://docs.bokeh.org/en/latest/docs/user_guide/server.html\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"e5a17ef6-ba69-4120-8f3f-4ea61e0645b2\" data-root-id=\"p1054\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"7f05e5d4-46ed-4978-8a63-8a45c2d8cce4\":{\"version\":\"3.5.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Column\",\"id\":\"p1054\",\"attributes\":{\"children\":[{\"type\":\"object\",\"name\":\"DatePicker\",\"id\":\"p1053\",\"attributes\":{\"disabled_dates\":null,\"enabled_dates\":null,\"title\":\"Select Date\",\"min_date\":\"2010-01-01\",\"max_date\":\"2022-12-31\",\"value\":\"2018-11-30\"}},{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1001\",\"attributes\":{\"width\":800,\"height\":800,\"x_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1010\",\"attributes\":{\"start\":11000000,\"end\":16000000}},\"y_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1011\",\"attributes\":{\"start\":-4500000,\"end\":-1000000}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1012\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1013\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1008\",\"attributes\":{\"text\":\"Heat and Cold Spikes on 2018-11-30\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"TileRenderer\",\"id\":\"p1038\",\"attributes\":{\"tile_source\":{\"type\":\"object\",\"name\":\"WMTSTileSource\",\"id\":\"p1037\",\"attributes\":{\"url\":\"https://c.tile.openstreetmap.org/{Z}/{X}/{Y}.png\"}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1049\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1040\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1041\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1042\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[16832542.279207345,12897531.863054074]],[\"y\",[-4011198.6473075734,-3756814.7353761178]],[\"color\",[\"red\",\"blue\"]],[\"size\",[10,10]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1050\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1051\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1046\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"field\",\"field\":\"size\"},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1047\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"field\",\"field\":\"size\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1048\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"field\",\"field\":\"size\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1009\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1024\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1025\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1026\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1027\",\"attributes\":{\"syncable\":false,\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"handles\":{\"type\":\"object\",\"name\":\"BoxInteractionHandles\",\"id\":\"p1033\",\"attributes\":{\"all\":{\"type\":\"object\",\"name\":\"AreaVisuals\",\"id\":\"p1032\",\"attributes\":{\"fill_color\":\"white\",\"hover_fill_color\":\"lightgray\"}}}}}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1034\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1035\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1036\"},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1052\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":[[\"Lat\",\"@y\"],[\"Lon\",\"@x\"]]}}]}},\"left\":[{\"type\":\"object\",\"name\":\"MercatorAxis\",\"id\":\"p1019\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"MercatorTicker\",\"id\":\"p1020\",\"attributes\":{\"mantissas\":[1,2,5],\"dimension\":\"lat\"}},\"formatter\":{\"type\":\"object\",\"name\":\"MercatorTickFormatter\",\"id\":\"p1021\",\"attributes\":{\"dimension\":\"lat\"}},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1022\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"MercatorAxis\",\"id\":\"p1014\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"MercatorTicker\",\"id\":\"p1015\",\"attributes\":{\"mantissas\":[1,2,5],\"dimension\":\"lon\"}},\"formatter\":{\"type\":\"object\",\"name\":\"MercatorTickFormatter\",\"id\":\"p1016\",\"attributes\":{\"dimension\":\"lon\"}},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1017\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1018\",\"attributes\":{\"axis\":{\"id\":\"p1014\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1023\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1019\"}}}]}}]}}]}};\n  const render_items = [{\"docid\":\"7f05e5d4-46ed-4978-8a63-8a45c2d8cce4\",\"roots\":{\"p1054\":\"e5a17ef6-ba69-4120-8f3f-4ea61e0645b2\"},\"root_ids\":[\"p1054\"]}];\n  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1054"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook, curdoc\n",
    "from bokeh.models import HoverTool, WMTSTileSource, ColumnDataSource\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models.widgets import DatePicker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "# Sample dataset for illustration\n",
    "datasets = {\n",
    "    \"dataset_1\": {\"attrs\": {\"geospatial_lat_max\": -33.8688, \"geospatial_lon_max\": 151.2093},\n",
    "                  \"TIME\": np.array(['2018-11-30T00:00:00'], dtype='datetime64[ns]'),\n",
    "                  \"TEMP_HEAT_SPIKE\": np.array([1]), \"TEMP_COLD_SPIKE\": np.array([np.nan])},\n",
    "    \"dataset_2\": {\"attrs\": {\"geospatial_lat_max\": -31.9505, \"geospatial_lon_max\": 115.8605},\n",
    "                  \"TIME\": np.array(['2018-11-30T00:00:00'], dtype='datetime64[ns]'),\n",
    "                  \"TEMP_HEAT_SPIKE\": np.array([np.nan]), \"TEMP_COLD_SPIKE\": np.array([1])}\n",
    "}\n",
    "\n",
    "# Function to convert lat/lon to Mercator projection\n",
    "def lon_lat_to_mercator(lon, lat):\n",
    "    k = 6378137\n",
    "    x = lon * (k * np.pi / 180.0)\n",
    "    y = np.log(np.tan((90 + lat) * np.pi / 360.0)) * k\n",
    "    return x, y\n",
    "\n",
    "# Function to convert date to \"days since 1950-01-01\"\n",
    "def date_to_days_since_1950(date):\n",
    "    ref_date = pd.to_datetime(\"1950-01-01\")\n",
    "    delta = date - ref_date\n",
    "    return delta.days\n",
    "\n",
    "# Set up Bokeh figure with custom tile provider\n",
    "p = figure(x_range=(11000000, 16000000), y_range=(-4500000, -1000000), \n",
    "           height=800, width=800,\n",
    "           x_axis_type=\"mercator\", y_axis_type=\"mercator\")\n",
    "\n",
    "tile_url = \"https://c.tile.openstreetmap.org/{Z}/{X}/{Y}.png\"\n",
    "p.add_tile(WMTSTileSource(url=tile_url))\n",
    "\n",
    "# Set up data source for interactive updating\n",
    "source = ColumnDataSource(data=dict(x=[], y=[], color=[], size=[]))\n",
    "\n",
    "p.circle(x='x', y='y', color='color', size='size', source=source, line_color='black', line_width=1.5)\n",
    "\n",
    "hover = HoverTool(tooltips=[(\"Lat\", \"@y\"), (\"Lon\", \"@x\")])\n",
    "p.add_tools(hover)\n",
    "\n",
    "# Function to update the plot based on the selected date\n",
    "def update_plot_bokeh_interactive(attr, old, new):\n",
    "    selected_date = pd.to_datetime(date_picker.value)\n",
    "    target_days = date_to_days_since_1950(selected_date)\n",
    "    \n",
    "    # Clear current data\n",
    "    new_data = dict(x=[], y=[], color=[], size=[])\n",
    "    \n",
    "    # Plot markers based on dataset\n",
    "    for folder, ds in datasets.items():\n",
    "        lat = ds['attrs']['geospatial_lat_max']\n",
    "        lon = ds['attrs']['geospatial_lon_max']\n",
    "        \n",
    "        time_in_days = (ds['TIME'] - np.datetime64(\"1950-01-01\")) / np.timedelta64(1, 'D')\n",
    "        \n",
    "        date_idx = np.isclose(time_in_days, target_days, atol=0.5)\n",
    "        \n",
    "        if date_idx.any():\n",
    "            temp_heat_spike = ds['TEMP_HEAT_SPIKE'][date_idx]\n",
    "            temp_cold_spike = ds['TEMP_COLD_SPIKE'][date_idx]\n",
    "            \n",
    "            lon_merc, lat_merc = lon_lat_to_mercator(lon, lat)\n",
    "            \n",
    "            if not pd.isna(temp_heat_spike).all():\n",
    "                new_data['x'].append(lon_merc)\n",
    "                new_data['y'].append(lat_merc)\n",
    "                new_data['color'].append(\"red\")\n",
    "                new_data['size'].append(10)\n",
    "            elif not pd.isna(temp_cold_spike).all():\n",
    "                new_data['x'].append(lon_merc)\n",
    "                new_data['y'].append(lat_merc)\n",
    "                new_data['color'].append(\"blue\")\n",
    "                new_data['size'].append(10)\n",
    "    \n",
    "    # Update data source\n",
    "    source.data = new_data\n",
    "    p.title.text = f'Heat and Cold Spikes on {selected_date.date()}'\n",
    "\n",
    "# Create a DatePicker widget\n",
    "date_picker = DatePicker(title=\"Select Date\", value=\"2018-11-30\", min_date=\"2010-01-01\", max_date=\"2022-12-31\")\n",
    "date_picker.on_change('value', update_plot_bokeh_interactive)\n",
    "\n",
    "# Initial update for the plot\n",
    "update_plot_bokeh_interactive(None, None, None)\n",
    "\n",
    "# Layout and display\n",
    "layout = column(date_picker, p)\n",
    "curdoc().add_root(layout)\n",
    "show(layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt at plotly plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca8c06ea51948458d3a1ad63a8b3058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=Timestamp('2018-11-30 00:00:00'), description='Select Date', step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edb62f673f5417b8dd1d3b32a517c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'hoverinfo': 'text',\n",
       "              'lat': [-42.52, -42.52, -34.02, -34.02, -34.02, -34.02, -34.02,\n",
       "                      -34.02, -34.03, -34.03, -34.03, -34.03, -34.03, -34.03,\n",
       "                      -34.03, -31.93, -31.93, -31.93, -31.93],\n",
       "              'lon': [148.3, 148.3, 151.25, 151.25, 151.25, 151.25, 151.25,\n",
       "                      151.25, 151.27, 151.27, 151.27, 151.27, 151.27, 151.27,\n",
       "                      151.27, 115.45, 115.45, 115.45, 115.45],\n",
       "              'marker': {'color': [red, red, black, black, black, black, black,\n",
       "                                   black, black, black, red, red, black, red, red,\n",
       "                                   blue, blue, black, blue],\n",
       "                         'line': {'color': 'black', 'width': 2},\n",
       "                         'opacity': 0.6,\n",
       "                         'size': 10,\n",
       "                         'symbol': [circle, circle, circle-open, circle-open,\n",
       "                                    circle-open, circle-open, circle-open, circle-\n",
       "                                    open, circle-open, circle-open, circle, circle,\n",
       "                                    circle-open, circle, circle, circle, circle,\n",
       "                                    circle-open, circle]},\n",
       "              'mode': 'markers',\n",
       "              'text': [Heat Spike, Heat Spike, No Data, No Data, No Data, No Data,\n",
       "                       No Data, No Data, No Data, No Data, Heat Spike, Heat Spike,\n",
       "                       No Data, Heat Spike, Heat Spike, Cold Spike, Cold Spike, No\n",
       "                       Data, Cold Spike],\n",
       "              'type': 'scattergeo',\n",
       "              'uid': '64c291f8-4828-4751-bb29-751aa4e8dfad'}],\n",
       "    'layout': {'autosize': True,\n",
       "               'geo': {'center': {'lat': -27.0, 'lon': 135.0},\n",
       "                       'coastlinecolor': 'black',\n",
       "                       'lakecolor': 'lightblue',\n",
       "                       'landcolor': 'lightgrey',\n",
       "                       'lataxis': {'range': [-50, -10]},\n",
       "                       'lonaxis': {'range': [100, 160]},\n",
       "                       'oceancolor': 'lightblue',\n",
       "                       'projection': {'type': 'mercator'},\n",
       "                       'scope': 'world',\n",
       "                       'showlakes': True,\n",
       "                       'showland': True,\n",
       "                       'showocean': True,\n",
       "                       'showrivers': True},\n",
       "               'height': 800,\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Heat and Cold Spikes on 2018-11-30 00:00:00'},\n",
       "               'width': 1000}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Initialize a Plotly FigureWidget object\n",
    "fig = go.FigureWidget()\n",
    "\n",
    "# Function to update the plot\n",
    "def update_plot(date):\n",
    "    # Convert selected date to datetime\n",
    "    target_date = pd.to_datetime(date)\n",
    "    \n",
    "    # Prepare lists to hold marker data\n",
    "    lons = []\n",
    "    lats = []\n",
    "    colors = []\n",
    "    text = []\n",
    "    symbols = []\n",
    "\n",
    "    # Iterate over datasets to gather marker data\n",
    "    for folder_key, df in dataframes.items():\n",
    "        # Filter the DataFrame by the selected date\n",
    "        date_idx = df['TIME'].dt.normalize() == target_date.normalize()\n",
    "\n",
    "        # If any rows match the date, gather the data for plotting\n",
    "        if date_idx.any():\n",
    "            # Iterate over the rows that match the date\n",
    "            for idx, row in df[date_idx].iterrows():\n",
    "                lat = row['lat']\n",
    "                lon = row['lon']\n",
    "                temp_heat_spike = row['TEMP_HEAT_SPIKE']\n",
    "                temp_cold_spike = row['TEMP_COLD_SPIKE']\n",
    "\n",
    "                # Determine the marker color and symbol based on spike data\n",
    "                if not pd.isna(temp_heat_spike):\n",
    "                    colors.append('red')\n",
    "                    text.append('Heat Spike')\n",
    "                    symbols.append('circle')  # Solid circle for heat spikes\n",
    "                elif not pd.isna(temp_cold_spike):\n",
    "                    colors.append('blue')\n",
    "                    text.append('Cold Spike')\n",
    "                    symbols.append('circle')  # Solid circle for cold spikes\n",
    "                else:\n",
    "                    colors.append('black')\n",
    "                    text.append('No Data')\n",
    "                    symbols.append('circle-open')  # Hollow circle for no data\n",
    "                \n",
    "                # Add lat/lon to the lists\n",
    "                lons.append(lon)\n",
    "                lats.append(lat)\n",
    "\n",
    "    # Update the traces in the FigureWidget\n",
    "    with fig.batch_update():\n",
    "        fig.data = []  # Clear existing traces\n",
    "        \n",
    "        fig.add_trace(go.Scattergeo(\n",
    "            lon=lons,\n",
    "            lat=lats,\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color=colors,\n",
    "                symbol=symbols,  # Use symbols to set marker shapes\n",
    "                line=dict(\n",
    "                    width=2,\n",
    "                    color='black'\n",
    "                ),\n",
    "                opacity=0.6\n",
    "            ),\n",
    "            text=text,\n",
    "            hoverinfo='text'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'Heat and Cold Spikes on {date}',\n",
    "            geo=dict(\n",
    "                scope='world',\n",
    "                projection_type='mercator',\n",
    "                center=dict(lat=-27.0, lon=135.0),  # Center around Australia\n",
    "                projection=dict(\n",
    "                    type='mercator'\n",
    "                ),\n",
    "                showland=True,\n",
    "                landcolor='lightgrey',\n",
    "                coastlinecolor='black',\n",
    "                showocean=True,\n",
    "                oceancolor='lightblue',\n",
    "                showlakes=True,\n",
    "                lakecolor='lightblue',\n",
    "                showrivers=True,\n",
    "                lonaxis=dict(\n",
    "                    range=[100, 160]  # Adjust longitude bounds to cover all of Australia\n",
    "                ),\n",
    "                lataxis=dict(\n",
    "                    range=[-50, -10]  # Adjust latitude bounds to cover all of Australia\n",
    "                )\n",
    "            ),\n",
    "            autosize=True,\n",
    "            height=800,  # Increase the height of the figure\n",
    "            width=1000   # Increase the width of the figure\n",
    "        )\n",
    "\n",
    "# Create a date picker widget\n",
    "date_picker = widgets.DatePicker(\n",
    "    description='Select Date',\n",
    "    value=pd.to_datetime(\"2018-11-30\")\n",
    ")\n",
    "\n",
    "# Create an interactive function to trigger the plot update when the date changes\n",
    "interactive_plot = widgets.interactive(update_plot, date=date_picker)\n",
    "\n",
    "# Display the date picker and plot together\n",
    "display(date_picker, fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to create a time slider instead of drop down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# Function to convert date to \"days since 1950-01-01\"\n",
    "def date_to_days_since_1950(date):\n",
    "    ref_date = pd.to_datetime(\"1950-01-01\")\n",
    "    delta = date - ref_date\n",
    "    return delta.days\n",
    "\n",
    "# Function to convert \"days since 1950-01-01\" to a date\n",
    "def days_since_1950_to_date(days):\n",
    "    ref_date = pd.to_datetime(\"1950-01-01\")\n",
    "    return ref_date + pd.to_timedelta(days, unit='D')\n",
    "\n",
    "# Function to update the plot\n",
    "def update_plot(days):\n",
    "    # Convert selected days to a date\n",
    "    date = days_since_1950_to_date(days)\n",
    "    \n",
    "    # Create a figure and a map with coastlines\n",
    "    fig, ax = plt.subplots(figsize=(12, 12), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    ax.coastlines(resolution='50m')\n",
    "    ax.add_feature(cfeature.LAND, edgecolor='black', facecolor='lightgrey')\n",
    "    ax.set_extent([110, 160, -45, -10], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Iterate over datasets to plot markers\n",
    "    for folder, ds in datasets.items():\n",
    "        lat = ds.attrs.get('geospatial_lat_max')\n",
    "        lon = ds.attrs.get('geospatial_lon_max')\n",
    "        \n",
    "        if lat is not None and lon is not None:\n",
    "            # TIME is already in datetime64 format, so no need for timedelta conversion\n",
    "            time_in_days = (ds['TIME'].values - np.datetime64(\"1950-01-01\")) / np.timedelta64(1, 'D')\n",
    "\n",
    "            # Find the index for the selected date in days since 1950\n",
    "            date_idx = np.isclose(time_in_days, days, atol=0.5)  # use a tolerance for floating point comparisons\n",
    "            \n",
    "            if date_idx.any():\n",
    "                temp_heat_spike = ds['TEMP_HEAT_SPIKE'].values[date_idx]\n",
    "                temp_cold_spike = ds['TEMP_COLD_SPIKE'].values[date_idx]\n",
    "                \n",
    "                if not pd.isna(temp_heat_spike).all():\n",
    "                    ax.plot(lon, lat, 'o', markersize=10, color='red', markeredgecolor='black', markeredgewidth=1.5,\n",
    "                            transform=ccrs.PlateCarree())\n",
    "                elif not pd.isna(temp_cold_spike).all():\n",
    "                    ax.plot(lon, lat, 'o', markersize=10, color='blue', markeredgecolor='black', markeredgewidth=1.5,\n",
    "                            transform=ccrs.PlateCarree())\n",
    "                else:\n",
    "                    ax.text(lon, lat, 'O', fontsize=15, color='black', ha='center', va='center',\n",
    "                            transform=ccrs.PlateCarree())\n",
    "    \n",
    "    ax.set_title(f'Heat and Cold Spikes on {date.date()}')\n",
    "    plt.show()\n",
    "\n",
    "# Determine the maximum number of days since 1950 based on the most recent dataset's date\n",
    "latest_date = pd.to_datetime(\"today\")  # Replace with the latest date in your data, or use today's date\n",
    "max_days = date_to_days_since_1950(latest_date)\n",
    "\n",
    "# Create a slider with the correct range\n",
    "date_slider = widgets.IntSlider(\n",
    "    value=date_to_days_since_1950(pd.to_datetime(\"2018-11-30\")),  # Initial value\n",
    "    min=0,  # Start from 1950-01-01\n",
    "    max=max_days,  # Maximum number of days until today or your latest data\n",
    "    step=1,  # Step in days\n",
    "    description='Days since 1950',\n",
    "    layout=widgets.Layout(width='800px')  # Adjust width of the slider\n",
    ")\n",
    "\n",
    "# Create an interactive function to trigger the plot update when the slider changes\n",
    "interactive_plot = widgets.interactive(update_plot, days=date_slider)\n",
    "\n",
    "# Display the slider and plot without duplicating the slider\n",
    "widgets.VBox([interactive_plot])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atempt to use Plotly with HTML output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Add traces for all dates\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m dates:\n\u001b[1;32m---> 62\u001b[0m     \u001b[43madd_traces_for_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Create dropdown buttons\u001b[39;00m\n\u001b[0;32m     65\u001b[0m date_buttons \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     66\u001b[0m     {\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: date,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m     } \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m dates\n\u001b[0;32m     74\u001b[0m ]\n",
      "Cell \u001b[1;32mIn[34], line 22\u001b[0m, in \u001b[0;36madd_traces_for_date\u001b[1;34m(date_str)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder_key, df \u001b[38;5;129;01min\u001b[39;00m dataframes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     20\u001b[0m     date_idx \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIME\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate \u001b[38;5;241m==\u001b[39m date\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdate_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m df[date_idx]\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     24\u001b[0m             lat, lon \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bstepin\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\pandas\\core\\series.py:6471\u001b[0m, in \u001b[0;36mSeries.any\u001b[1;34m(self, axis, bool_only, skipna, **kwargs)\u001b[0m\n\u001b[0;32m   6469\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_logical_func((), kwargs, fname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6470\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 6471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanany\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43many\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6474\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbool\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6478\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bstepin\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6452\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[0;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6456\u001b[0m     )\n\u001b[1;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bstepin\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\pandas\\core\\nanops.py:520\u001b[0m, in \u001b[0;36mnanany\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;124;03mCheck if any elements along an axis evaluate to True.\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03mFalse\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miub\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;66;03m# GH#26032 fastpath\u001b[39;00m\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[bool_, ndarray]\",\u001b[39;00m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;66;03m# expected \"bool\")\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;66;03m# GH#34479\u001b[39;00m\n\u001b[0;32m    524\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with datetime64 dtypes is deprecated and will raise in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture version. Use (obj != pd.Timestamp(0)).any() instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    528\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    529\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bstepin\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\numpy\\core\\_methods.py:58\u001b[0m, in \u001b[0;36m_any\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_any\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_any\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extract unique dates for dropdown\n",
    "dates = []\n",
    "for df in dataframes.values():\n",
    "    dates.extend(df['TIME'].dt.date.unique())\n",
    "\n",
    "# Remove duplicates and sort dates\n",
    "dates = sorted(set(dates))\n",
    "dates = [pd.Timestamp(date).strftime('%Y-%m-%d') for date in dates]\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "def add_traces_for_date(date_str):\n",
    "    date = pd.to_datetime(date_str).date()\n",
    "    \n",
    "    # Prepare lists to hold marker data\n",
    "    lons, lats, colors, text, symbols = [], [], [], [], []\n",
    "    \n",
    "    for folder_key, df in dataframes.items():\n",
    "        date_idx = df['TIME'].dt.date == date\n",
    "        \n",
    "        if date_idx.any():\n",
    "            for idx, row in df[date_idx].iterrows():\n",
    "                lat, lon = row['lat'], row['lon']\n",
    "                temp_heat_spike = row['TEMP_HEAT_SPIKE']\n",
    "                temp_cold_spike = row['TEMP_COLD_SPIKE']\n",
    "                \n",
    "                if not pd.isna(temp_heat_spike):\n",
    "                    colors.append('red')\n",
    "                    text.append('Heat Spike')\n",
    "                    symbols.append('circle')\n",
    "                elif not pd.isna(temp_cold_spike):\n",
    "                    colors.append('blue')\n",
    "                    text.append('Cold Spike')\n",
    "                    symbols.append('circle')\n",
    "                else:\n",
    "                    colors.append('black')\n",
    "                    text.append('No Data')\n",
    "                    symbols.append('circle-open')\n",
    "                \n",
    "                lons.append(lon)\n",
    "                lats.append(lat)\n",
    "    \n",
    "    fig.add_trace(go.Scattergeo(\n",
    "        lon=lons,\n",
    "        lat=lats,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color=colors,\n",
    "            symbol=symbols,\n",
    "            line=dict(width=2, color='black'),\n",
    "            opacity=0.6\n",
    "        ),\n",
    "        text=text,\n",
    "        hoverinfo='text',\n",
    "        name=f'Data for {date_str}'\n",
    "    ))\n",
    "\n",
    "# Add traces for all dates\n",
    "for date in dates:\n",
    "    add_traces_for_date(date)\n",
    "\n",
    "# Create dropdown buttons\n",
    "date_buttons = [\n",
    "    {\n",
    "        \"label\": date,\n",
    "        \"method\": \"update\",\n",
    "        \"args\": [\n",
    "            {\"visible\": [trace.name == f'Data for {date}' for trace in fig.data]},\n",
    "            {\"title\": f'Heat and Cold Spikes on {date}'}\n",
    "        ]\n",
    "    } for date in dates\n",
    "]\n",
    "\n",
    "# Update layout with dropdowns\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        {\n",
    "            \"buttons\": date_buttons,\n",
    "            \"direction\": \"down\",\n",
    "            \"pad\": {\"r\": 10, \"t\": 10},\n",
    "            \"showactive\": True,\n",
    "            \"x\": 0.1,\n",
    "            \"xanchor\": \"left\",\n",
    "            \"y\": 1.2,\n",
    "            \"yanchor\": \"top\",\n",
    "            \"title\": \"Select Date\"\n",
    "        }\n",
    "    ],\n",
    "    geo=dict(\n",
    "        scope='world',\n",
    "        projection_type='mercator',\n",
    "        center=dict(lat=-27.0, lon=135.0),\n",
    "        projection=dict(type='mercator'),\n",
    "        showland=True,\n",
    "        landcolor='lightgrey',\n",
    "        coastlinecolor='black',\n",
    "        showocean=True,\n",
    "        oceancolor='lightblue',\n",
    "        lonaxis=dict(range=[100, 160]),\n",
    "        lataxis=dict(range=[-50, -10])\n",
    "    ),\n",
    "    title=\"Heat and Cold Spikes\",\n",
    "    height=800,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "# Save the figure as an HTML file\n",
    "fig.write_html(\"interactive_map.html\", include_plotlyjs='cdn')\n",
    "\n",
    "# Optionally save the figure as a JSON file (data only, without interactivity)\n",
    "fig.write_json(\"interactive_map.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming dataframes is already loaded and available\n",
    "# Filter for November 2018\n",
    "def filter_november_dataframes(dfs):\n",
    "    filtered_dfs = {}\n",
    "    for key, df in dfs.items():\n",
    "        # Ensure TIME is in datetime format\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df['TIME']):\n",
    "            df['TIME'] = pd.to_datetime(df['TIME'])\n",
    "        \n",
    "        # Filter only for November 2018\n",
    "        df_november = df[(df['TIME'] >= '2018-11-01') & (df['TIME'] < '2018-12-01')]\n",
    "        filtered_dfs[key] = df_november\n",
    "    return filtered_dfs\n",
    "\n",
    "# Apply the filter to the dataframes\n",
    "filtered_dataframes = filter_november_dataframes(dataframes)\n",
    "\n",
    "# Extract unique dates for dropdown (within November 2018)\n",
    "dates = []\n",
    "for df in filtered_dataframes.values():\n",
    "    dates.extend(df['TIME'].dt.date.unique())\n",
    "\n",
    "# Remove duplicates and sort dates\n",
    "dates = sorted(set(dates))\n",
    "dates = [pd.Timestamp(date).strftime('%Y-%m-%d') for date in dates]\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Function to assign colors and categories based on deviation from percentiles\n",
    "def assign_heat_category(deviation, interval):\n",
    "    if deviation <= interval:\n",
    "        return 0, 'yellow'\n",
    "    elif deviation <= 2 * interval:\n",
    "        return 1, 'orange'\n",
    "    elif deviation <= 3 * interval:\n",
    "        return 2, 'red'\n",
    "    else:\n",
    "        return 3, 'maroon'\n",
    "\n",
    "def assign_cold_category(deviation, interval):\n",
    "    if deviation <= interval:\n",
    "        return 0, 'turquoise'\n",
    "    elif deviation <= 2 * interval:\n",
    "        return 1, 'cyan'\n",
    "    elif deviation <= 3 * interval:\n",
    "        return 2, 'royalblue'\n",
    "    else:\n",
    "        return 3, 'navy'\n",
    "\n",
    "# Function to add traces for a specific date\n",
    "def add_traces_for_date(date_str):\n",
    "    date = pd.to_datetime(date_str).date()\n",
    "    \n",
    "    # Prepare lists to hold marker data\n",
    "    lons, lats, colors, sizes, text, symbols = [], [], [], [], [], []\n",
    "    \n",
    "    for folder_key, df in filtered_dataframes.items():\n",
    "        date_idx = df['TIME'].dt.date == date\n",
    "        \n",
    "        if date_idx.any():\n",
    "            for idx, row in df[date_idx].iterrows():\n",
    "                lat, lon = row['lat'], row['lon']\n",
    "                temp_heat_spike = row['TEMP_HEAT_SPIKE']\n",
    "                temp_cold_spike = row['TEMP_COLD_SPIKE']\n",
    "                temp_per90 = row['TEMP_PER90']\n",
    "                temp_per10 = row['TEMP_PER10']\n",
    "                \n",
    "                if not pd.isna(temp_heat_spike):\n",
    "                    interval = temp_per90 - row['TEMP_MEAN']\n",
    "                    deviation = temp_heat_spike - temp_per90\n",
    "                    category, color = assign_heat_category(deviation, interval)\n",
    "                    colors.append(color)\n",
    "                    sizes.append(10 + deviation * 2)\n",
    "                    text.append(f'Heat Spike: +{deviation:.2f}°C above 90th percentile\\nCategory: {category}')\n",
    "                    symbols.append('circle')\n",
    "                \n",
    "                elif not pd.isna(temp_cold_spike):\n",
    "                    interval = row['TEMP_MEAN'] - temp_per10\n",
    "                    deviation = temp_per10 - temp_cold_spike\n",
    "                    category, color = assign_cold_category(deviation, interval)\n",
    "                    colors.append(color)\n",
    "                    sizes.append(10 + deviation * 2)\n",
    "                    text.append(f'Cold Spike: -{deviation:.2f}°C below 10th percentile\\nCategory: {category}')\n",
    "                    symbols.append('circle')\n",
    "                \n",
    "                else:\n",
    "                    colors.append('black')\n",
    "                    sizes.append(8)\n",
    "                    text.append('No Data')\n",
    "                    symbols.append('circle-open')\n",
    "                \n",
    "                lons.append(lon)\n",
    "                lats.append(lat)\n",
    "    \n",
    "    # Only add a trace if there is data for the date\n",
    "    if lons and lats:\n",
    "        fig.add_trace(go.Scattergeo(\n",
    "            lon=lons,\n",
    "            lat=lats,\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=sizes,\n",
    "                color=colors,\n",
    "                symbol=symbols,\n",
    "                line=dict(width=2, color='black'),\n",
    "                opacity=0.6\n",
    "            ),\n",
    "            text=text,\n",
    "            hoverinfo='text',\n",
    "            name=f'Data for {date_str}',\n",
    "            visible=False  # Start with all traces hidden\n",
    "        ))\n",
    "\n",
    "# Add traces for all dates in November 2018\n",
    "for date in dates:\n",
    "    add_traces_for_date(date)\n",
    "\n",
    "# Show only the first date's data by default\n",
    "if fig.data:\n",
    "    fig.data[0].visible = True\n",
    "\n",
    "# Create dropdown buttons for each date\n",
    "date_buttons = [\n",
    "    {\n",
    "        \"label\": date,\n",
    "        \"method\": \"update\",\n",
    "        \"args\": [\n",
    "            {\"visible\": [trace.name == f'Data for {date}' for trace in fig.data]},\n",
    "            {\"title\": f'Heat and Cold Spikes on {date}'}\n",
    "        ]\n",
    "    } for date in dates\n",
    "]\n",
    "\n",
    "# Update layout with dropdowns\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        {\n",
    "            \"buttons\": date_buttons,\n",
    "            \"direction\": \"down\",\n",
    "            \"pad\": {\"r\": 10, \"t\": 10},\n",
    "            \"showactive\": True,\n",
    "            \"x\": 0.1,\n",
    "            \"xanchor\": \"left\",\n",
    "            \"y\": 1.2,\n",
    "            \"yanchor\": \"top\"\n",
    "        }\n",
    "    ],\n",
    "    geo=dict(\n",
    "        scope='world',\n",
    "        projection_type='mercator',\n",
    "        center=dict(lat=-27.0, lon=135.0),\n",
    "        projection=dict(type='mercator'),\n",
    "        showland=True,\n",
    "        landcolor='lightgrey',\n",
    "        coastlinecolor='black',\n",
    "        showocean=True,\n",
    "        oceancolor='lightblue',\n",
    "        lonaxis=dict(range=[100, 160]),\n",
    "        lataxis=dict(range=[-50, -10])\n",
    "    ),\n",
    "    title=\"Heat and Cold Spikes\",\n",
    "    height=800,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "# Save the figure as an HTML file\n",
    "fig.write_html(\"interactive_map.html\", include_plotlyjs='cdn')\n",
    "\n",
    "# Optionally save the figure as a JSON file (data only, without interactivity)\n",
    "fig.write_json(\"interactive_map.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
